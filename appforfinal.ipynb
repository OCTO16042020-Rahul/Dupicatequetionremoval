{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 is not supported on this machine (please install/reinstall h5py for optimal experience)\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\Anaconda3\\lib\\site-packages\\tflearn\\helpers\\trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Ningesh\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ningesh\\049 AutoQA\\model.tflearn\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Ningesh\\049 AutoQA\\model.tflearn\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [10/Jul/2020 13:37:04] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Jul/2020 13:37:13] \"\u001b[32mPOST /login HTTP/1.1\u001b[0m\" 302 -\n",
      "127.0.0.1 - - [10/Jul/2020 13:37:13] \"\u001b[37mGET /duplicatedetection HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [10/Jul/2020 13:37:26] \"\u001b[37mGET /get?msg=what+is+machine+learning HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.8802510e-33 1.0286125e-31 0.0000000e+00 1.2716047e-34 2.7784532e-22\n",
      "  6.4642446e-20 0.0000000e+00 1.2292070e-37 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3073921e-36\n",
      "  1.6498924e-32 0.0000000e+00 0.0000000e+00 6.4967318e-19 3.5595696e-15\n",
      "  3.9218307e-17 0.0000000e+00 9.3144378e-14 0.0000000e+00 4.8956329e-20\n",
      "  0.0000000e+00 0.0000000e+00 3.5553047e-32 2.7539063e-24 0.0000000e+00\n",
      "  0.0000000e+00 5.8856437e-37 4.4621715e-19 5.7120771e-36 2.4814686e-05\n",
      "  5.0090193e-26 1.3501795e-22 1.9131768e-04 0.0000000e+00 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00 8.5169262e-18 0.0000000e+00 6.1485093e-37\n",
      "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1944880e-36\n",
      "  0.0000000e+00 5.0879610e-25 2.0018779e-15 9.8209733e-01 2.2300412e-35\n",
      "  0.0000000e+00 5.0219925e-33 4.5246010e-25 4.7885258e-19 1.7120341e-02\n",
      "  1.4462055e-16 1.7133576e-05 1.0365868e-20 6.5800270e-07 1.1324510e-06\n",
      "  1.3208696e-17 2.1947089e-32 0.0000000e+00 1.5392002e-33 5.3750320e-37\n",
      "  0.0000000e+00 1.8867742e-33 3.4412037e-17 1.3226528e-12 1.0849223e-11\n",
      "  8.1705159e-34 1.2608693e-38 1.7846209e-15 1.6382734e-14 0.0000000e+00\n",
      "  4.7022569e-25 8.0530604e-25 1.4689232e-17 6.1111227e-06 2.1624307e-25\n",
      "  3.3025218e-34 2.1016850e-13 1.5667212e-35 3.6852414e-04 6.8868866e-10\n",
      "  3.5391939e-29 4.7791368e-38 1.4081066e-20 6.9356233e-28 8.8024405e-27\n",
      "  1.7258943e-04]]\n",
      "53\n",
      "0.9820973\n",
      "input matches with question \n",
      " what is Machine Translation,Machine Translation,Machine Translation definition,define Machine Translation, with 0.9820973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:37:37] \"\u001b[37mGET /get?msg=python HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.20655455e-09 1.08140066e-05 9.73961534e-09 2.20560505e-05\n",
      "  1.31533865e-03 5.54761925e-07 7.76591638e-12 5.95588858e-07\n",
      "  3.32627081e-08 1.49208586e-06 1.63536996e-03 9.34462392e-08\n",
      "  6.76445197e-04 1.56031035e-07 1.01607520e-06 9.77849552e-08\n",
      "  4.26480528e-06 6.69302722e-07 6.81455480e-04 1.42263718e-06\n",
      "  3.20796266e-06 2.69376021e-10 2.14338783e-07 7.38833605e-10\n",
      "  5.63497655e-03 9.63010461e-05 2.19951821e-10 1.00448781e-11\n",
      "  5.27717035e-08 8.89412917e-08 6.04315574e-06 1.29623130e-01\n",
      "  1.68032329e-05 9.80031681e-11 1.94882523e-06 7.33240274e-11\n",
      "  1.22374786e-05 8.56159488e-04 2.20164753e-09 2.05518513e-09\n",
      "  4.95710083e-07 1.78160576e-07 1.04005425e-03 8.55187421e-10\n",
      "  7.84592794e-06 2.26221015e-08 6.83945678e-10 4.14213036e-06\n",
      "  6.24493595e-08 3.52639207e-09 6.15578529e-06 1.14125155e-01\n",
      "  1.90491210e-06 1.53007943e-06 3.02420524e-08 6.65397874e-06\n",
      "  7.64097795e-02 1.35149821e-05 1.23898648e-02 3.19746844e-02\n",
      "  1.45225017e-03 1.56584749e-04 3.69318198e-09 7.76312490e-08\n",
      "  3.05009962e-06 7.18863475e-07 7.82203870e-07 4.56777671e-12\n",
      "  1.41714153e-07 4.88033472e-03 1.49100355e-03 3.06808832e-03\n",
      "  1.07389678e-04 1.54357629e-08 2.85302260e-04 2.56944360e-04\n",
      "  4.61922842e-04 5.57567298e-01 4.60707508e-02 2.37965869e-09\n",
      "  1.89415800e-07 7.55901730e-10 4.60075853e-08 6.35678740e-03\n",
      "  1.06792856e-11 1.24301971e-03 7.02717717e-10 6.59300781e-07\n",
      "  7.97674090e-07 2.82797430e-09 7.13515011e-12 4.61721938e-10\n",
      "  1.45884060e-09 5.02747399e-10 4.40421081e-06 6.40111375e-06]]\n",
      "77\n",
      "0.5575673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:37:47] \"\u001b[37mGET /get?msg=what+is+java HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.59795438e-11 2.02828073e-06 3.01591996e-09 3.05040885e-07\n",
      "  1.53106739e-04 6.24959625e-07 8.78062746e-14 7.70807862e-09\n",
      "  3.54160479e-09 2.34720659e-07 2.56660220e-04 5.15323073e-09\n",
      "  1.51118575e-05 2.26636434e-08 9.44974829e-07 2.00354933e-08\n",
      "  3.30972725e-08 3.89895449e-09 2.06206529e-03 4.76525747e-06\n",
      "  1.94088670e-06 5.92838556e-11 1.85102316e-08 1.75910484e-11\n",
      "  2.69782753e-03 5.60044873e-06 1.03497098e-11 8.98097514e-13\n",
      "  2.34544317e-09 4.64501255e-08 7.71090569e-08 1.57505516e-02\n",
      "  8.78581034e-07 1.86873173e-12 1.25848396e-06 3.16545444e-12\n",
      "  4.23599801e-07 2.95349467e-03 3.33370900e-11 1.61972605e-11\n",
      "  9.35453226e-09 1.61647773e-09 3.01784230e-03 1.36814613e-11\n",
      "  9.40859024e-07 1.91732430e-09 1.06605461e-10 9.79991910e-08\n",
      "  6.23185115e-10 4.36523734e-10 7.11910957e-08 8.12728703e-02\n",
      "  4.17303823e-07 2.07985022e-06 2.98235159e-10 1.33267321e-07\n",
      "  7.89656676e-03 4.02819533e-05 2.56979745e-03 1.02623567e-01\n",
      "  1.10485137e-03 6.19538769e-05 8.28434932e-10 2.97488345e-08\n",
      "  4.69592260e-06 1.86730506e-06 1.10002395e-06 2.59011969e-13\n",
      "  6.00692873e-09 1.38605770e-04 4.86771110e-04 3.93055240e-03\n",
      "  2.03095842e-05 1.55042734e-08 1.42362306e-03 1.78026807e-04\n",
      "  8.50268952e-06 7.62585282e-01 5.34966681e-03 1.09576081e-11\n",
      "  4.43196171e-07 3.81188914e-10 1.04830358e-08 3.28235398e-03\n",
      "  1.87159229e-12 8.04808587e-05 3.30645539e-10 2.99729557e-08\n",
      "  2.28290514e-06 8.34855962e-10 2.83901483e-13 2.91841967e-11\n",
      "  9.20687832e-11 2.42164899e-10 3.66207746e-06 2.19665890e-06]]\n",
      "77\n",
      "0.7625853\n",
      "input matches with question \n",
      " what is Tokenization, Tokenization, Tokenization definition,define Tokenization, with 0.7625853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:38:15] \"\u001b[37mGET /get?msg=+prediction HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.20655455e-09 1.08140066e-05 9.73961534e-09 2.20560505e-05\n",
      "  1.31533865e-03 5.54761925e-07 7.76591638e-12 5.95588858e-07\n",
      "  3.32627081e-08 1.49208586e-06 1.63536996e-03 9.34462392e-08\n",
      "  6.76445197e-04 1.56031035e-07 1.01607520e-06 9.77849552e-08\n",
      "  4.26480528e-06 6.69302722e-07 6.81455480e-04 1.42263718e-06\n",
      "  3.20796266e-06 2.69376021e-10 2.14338783e-07 7.38833605e-10\n",
      "  5.63497655e-03 9.63010461e-05 2.19951821e-10 1.00448781e-11\n",
      "  5.27717035e-08 8.89412917e-08 6.04315574e-06 1.29623130e-01\n",
      "  1.68032329e-05 9.80031681e-11 1.94882523e-06 7.33240274e-11\n",
      "  1.22374786e-05 8.56159488e-04 2.20164753e-09 2.05518513e-09\n",
      "  4.95710083e-07 1.78160576e-07 1.04005425e-03 8.55187421e-10\n",
      "  7.84592794e-06 2.26221015e-08 6.83945678e-10 4.14213036e-06\n",
      "  6.24493595e-08 3.52639207e-09 6.15578529e-06 1.14125155e-01\n",
      "  1.90491210e-06 1.53007943e-06 3.02420524e-08 6.65397874e-06\n",
      "  7.64097795e-02 1.35149821e-05 1.23898648e-02 3.19746844e-02\n",
      "  1.45225017e-03 1.56584749e-04 3.69318198e-09 7.76312490e-08\n",
      "  3.05009962e-06 7.18863475e-07 7.82203870e-07 4.56777671e-12\n",
      "  1.41714153e-07 4.88033472e-03 1.49100355e-03 3.06808832e-03\n",
      "  1.07389678e-04 1.54357629e-08 2.85302260e-04 2.56944360e-04\n",
      "  4.61922842e-04 5.57567298e-01 4.60707508e-02 2.37965869e-09\n",
      "  1.89415800e-07 7.55901730e-10 4.60075853e-08 6.35678740e-03\n",
      "  1.06792856e-11 1.24301971e-03 7.02717717e-10 6.59300781e-07\n",
      "  7.97674090e-07 2.82797430e-09 7.13515011e-12 4.61721938e-10\n",
      "  1.45884060e-09 5.02747399e-10 4.40421081e-06 6.40111375e-06]]\n",
      "77\n",
      "0.5575673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:38:32] \"\u001b[37mGET /get?msg=flask HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.20655455e-09 1.08140066e-05 9.73961534e-09 2.20560505e-05\n",
      "  1.31533865e-03 5.54761925e-07 7.76591638e-12 5.95588858e-07\n",
      "  3.32627081e-08 1.49208586e-06 1.63536996e-03 9.34462392e-08\n",
      "  6.76445197e-04 1.56031035e-07 1.01607520e-06 9.77849552e-08\n",
      "  4.26480528e-06 6.69302722e-07 6.81455480e-04 1.42263718e-06\n",
      "  3.20796266e-06 2.69376021e-10 2.14338783e-07 7.38833605e-10\n",
      "  5.63497655e-03 9.63010461e-05 2.19951821e-10 1.00448781e-11\n",
      "  5.27717035e-08 8.89412917e-08 6.04315574e-06 1.29623130e-01\n",
      "  1.68032329e-05 9.80031681e-11 1.94882523e-06 7.33240274e-11\n",
      "  1.22374786e-05 8.56159488e-04 2.20164753e-09 2.05518513e-09\n",
      "  4.95710083e-07 1.78160576e-07 1.04005425e-03 8.55187421e-10\n",
      "  7.84592794e-06 2.26221015e-08 6.83945678e-10 4.14213036e-06\n",
      "  6.24493595e-08 3.52639207e-09 6.15578529e-06 1.14125155e-01\n",
      "  1.90491210e-06 1.53007943e-06 3.02420524e-08 6.65397874e-06\n",
      "  7.64097795e-02 1.35149821e-05 1.23898648e-02 3.19746844e-02\n",
      "  1.45225017e-03 1.56584749e-04 3.69318198e-09 7.76312490e-08\n",
      "  3.05009962e-06 7.18863475e-07 7.82203870e-07 4.56777671e-12\n",
      "  1.41714153e-07 4.88033472e-03 1.49100355e-03 3.06808832e-03\n",
      "  1.07389678e-04 1.54357629e-08 2.85302260e-04 2.56944360e-04\n",
      "  4.61922842e-04 5.57567298e-01 4.60707508e-02 2.37965869e-09\n",
      "  1.89415800e-07 7.55901730e-10 4.60075853e-08 6.35678740e-03\n",
      "  1.06792856e-11 1.24301971e-03 7.02717717e-10 6.59300781e-07\n",
      "  7.97674090e-07 2.82797430e-09 7.13515011e-12 4.61721938e-10\n",
      "  1.45884060e-09 5.02747399e-10 4.40421081e-06 6.40111375e-06]]\n",
      "77\n",
      "0.5575673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:38:37] \"\u001b[37mGET /get?msg=django HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.20655455e-09 1.08140066e-05 9.73961534e-09 2.20560505e-05\n",
      "  1.31533865e-03 5.54761925e-07 7.76591638e-12 5.95588858e-07\n",
      "  3.32627081e-08 1.49208586e-06 1.63536996e-03 9.34462392e-08\n",
      "  6.76445197e-04 1.56031035e-07 1.01607520e-06 9.77849552e-08\n",
      "  4.26480528e-06 6.69302722e-07 6.81455480e-04 1.42263718e-06\n",
      "  3.20796266e-06 2.69376021e-10 2.14338783e-07 7.38833605e-10\n",
      "  5.63497655e-03 9.63010461e-05 2.19951821e-10 1.00448781e-11\n",
      "  5.27717035e-08 8.89412917e-08 6.04315574e-06 1.29623130e-01\n",
      "  1.68032329e-05 9.80031681e-11 1.94882523e-06 7.33240274e-11\n",
      "  1.22374786e-05 8.56159488e-04 2.20164753e-09 2.05518513e-09\n",
      "  4.95710083e-07 1.78160576e-07 1.04005425e-03 8.55187421e-10\n",
      "  7.84592794e-06 2.26221015e-08 6.83945678e-10 4.14213036e-06\n",
      "  6.24493595e-08 3.52639207e-09 6.15578529e-06 1.14125155e-01\n",
      "  1.90491210e-06 1.53007943e-06 3.02420524e-08 6.65397874e-06\n",
      "  7.64097795e-02 1.35149821e-05 1.23898648e-02 3.19746844e-02\n",
      "  1.45225017e-03 1.56584749e-04 3.69318198e-09 7.76312490e-08\n",
      "  3.05009962e-06 7.18863475e-07 7.82203870e-07 4.56777671e-12\n",
      "  1.41714153e-07 4.88033472e-03 1.49100355e-03 3.06808832e-03\n",
      "  1.07389678e-04 1.54357629e-08 2.85302260e-04 2.56944360e-04\n",
      "  4.61922842e-04 5.57567298e-01 4.60707508e-02 2.37965869e-09\n",
      "  1.89415800e-07 7.55901730e-10 4.60075853e-08 6.35678740e-03\n",
      "  1.06792856e-11 1.24301971e-03 7.02717717e-10 6.59300781e-07\n",
      "  7.97674090e-07 2.82797430e-09 7.13515011e-12 4.61721938e-10\n",
      "  1.45884060e-09 5.02747399e-10 4.40421081e-06 6.40111375e-06]]\n",
      "77\n",
      "0.5575673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:38:54] \"\u001b[37mGET /get?msg=what+is+tokenization HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.71939161e-25 4.61210778e-23 1.90729224e-25\n",
      "  6.15954863e-22 7.64117174e-26 0.00000000e+00 2.40371284e-34\n",
      "  2.72060747e-26 2.72623903e-18 5.60944723e-14 1.72867480e-21\n",
      "  4.46449353e-18 1.28157407e-27 1.20431754e-20 2.02545317e-31\n",
      "  5.94927847e-31 5.87898062e-31 3.47707851e-06 8.51390948e-19\n",
      "  2.38216476e-16 2.38381932e-31 5.41356879e-33 0.00000000e+00\n",
      "  6.77785636e-07 1.11935568e-23 2.64702989e-35 0.00000000e+00\n",
      "  2.26306877e-37 5.07160428e-20 2.34293535e-23 2.38353010e-07\n",
      "  1.71349217e-25 0.00000000e+00 1.49898536e-21 0.00000000e+00\n",
      "  5.91531402e-30 1.04540199e-08 2.36027487e-31 1.10456174e-36\n",
      "  2.18644989e-29 9.13495773e-35 5.14665220e-11 0.00000000e+00\n",
      "  2.99263961e-15 2.48657339e-24 3.44570548e-36 8.44171742e-21\n",
      "  3.59940682e-28 6.26491761e-26 4.30377427e-26 2.21918711e-07\n",
      "  3.11862639e-30 1.46953175e-22 8.12885625e-36 1.84415203e-18\n",
      "  3.32369820e-13 1.06590925e-11 7.00200076e-08 4.49863045e-08\n",
      "  5.41726969e-17 4.76134682e-22 2.55162953e-37 1.06437421e-32\n",
      "  8.93879591e-24 4.57953530e-15 2.01984578e-14 0.00000000e+00\n",
      "  3.48435918e-26 1.73563708e-16 3.17407682e-07 1.11712950e-07\n",
      "  4.35178847e-16 7.89652843e-24 8.72701245e-10 5.92798390e-16\n",
      "  1.66327871e-24 9.99994874e-01 2.10301615e-15 0.00000000e+00\n",
      "  5.25129356e-19 5.70727188e-35 1.35767738e-26 1.71435674e-12\n",
      "  0.00000000e+00 1.88213442e-12 7.56306637e-36 1.30936681e-33\n",
      "  6.58753887e-23 3.48124925e-34 0.00000000e+00 0.00000000e+00\n",
      "  3.83377000e-36 6.01372107e-29 6.12203810e-13 4.02938475e-24]]\n",
      "77\n",
      "0.9999949\n",
      "input matches with question \n",
      " what is Tokenization, Tokenization, Tokenization definition,define Tokenization, with 0.9999949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:39:31] \"\u001b[37mGET /get?msg=What+Is+Pragmatic+Analysis+In+Nlp HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.89903434e-25 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.20439889e-25 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.84214562e-23 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 5.26825861e-10\n",
      "  1.70044944e-35 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  1.40360343e-37 1.52195234e-08 3.21031715e-31 3.71917892e-08\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 2.77195894e-37\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.87079937e-37 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 1.95740087e-26 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 4.29029026e-33 7.34887989e-24\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 4.18620624e-19\n",
      "  1.15313894e-35 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.62707809e-30 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 3.82372758e-35\n",
      "  0.00000000e+00 0.00000000e+00 3.44498486e-22 0.00000000e+00\n",
      "  1.43378367e-08 0.00000000e+00 3.76968758e-22 0.00000000e+00\n",
      "  0.00000000e+00 1.66425895e-08 9.99999881e-01 0.00000000e+00\n",
      "  1.47549184e-09 6.33511108e-30 0.00000000e+00 1.75586782e-34]]\n",
      "90\n",
      "0.9999999\n",
      "input matches with question \n",
      " What Is Pragmatic Analysis In Nlp,Pragmatic Analysis In Nlp, with 0.9999999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [10/Jul/2020 13:39:48] \"\u001b[37mGET /get?msg=what+is+Artificial+Intelligence HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.00933605e-38 0.00000000e+00 0.00000000e+00 1.18723857e-16\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 9.17217459e-31\n",
      "  0.00000000e+00 1.64086757e-35 2.93127401e-34 1.91236784e-22\n",
      "  1.21556754e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.18714573e-13 2.82280689e-06 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  2.85243519e-35 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 9.99763310e-01 5.68399818e-16\n",
      "  5.87775482e-38 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 3.02684060e-18 1.07972208e-19\n",
      "  1.42860568e-26 1.71834534e-24 0.00000000e+00 0.00000000e+00\n",
      "  6.25046198e-25 2.11722848e-35 0.00000000e+00 2.63596487e-08\n",
      "  1.11809175e-04 0.00000000e+00 1.40703893e-08 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 5.02288292e-26 2.10593313e-07\n",
      "  2.24848978e-26 0.00000000e+00 8.13509859e-29 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.95733548e-27 2.30391549e-07 1.23924235e-30 0.00000000e+00\n",
      "  1.06717905e-35 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  7.32476510e-21 0.00000000e+00 3.33427131e-37 1.74582706e-14\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 1.24103380e-10 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "30\n",
      "0.9997633\n",
      "input matches with question \n",
      " what is Artificial Intelligence,Artificial Intelligence,Artificial Intelligence definition,define Artificial Intelligence, with 0.9997633\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, session, url_for, redirect, jsonify\n",
    "import pymysql\n",
    "\n",
    "#=========\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "import numpy\n",
    "import tflearn\n",
    "import tensorflow\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import scipy.spatial\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "import math\n",
    "import warnings\n",
    "import sys\n",
    "#from sklearn.utils.extmath import np.dot\n",
    "\n",
    "#=========Database Connection===\n",
    "connection = pymysql.connect(host=\"localhost\", user=\"root\", password=\"\", database=\"063autoqa\")\n",
    "cursor = connection.cursor()\n",
    "#============start=======chatbot============\n",
    "#chatbot\n",
    "with open(\"QASystemCrypto.json\", encoding=\"utf8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "try:\n",
    "    with open(\"data.pickle\", \"rb\") as f:\n",
    "        words, labels, training, output = pickle.load(f)\n",
    "except:\n",
    "    words = []\n",
    "    labels = []\n",
    "    docs_x = []\n",
    "    docs_y = []\n",
    "\n",
    "    for intent in data[\"intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            wrds = nltk.word_tokenize(pattern)\n",
    "            words.extend(wrds)\n",
    "            docs_x.append(wrds)\n",
    "            # print(wrds)\n",
    "            docs_y.append(intent[\"tag\"])\n",
    "\n",
    "        if intent[\"tag\"] not in labels:\n",
    "            labels.append(intent[\"tag\"])\n",
    "\n",
    "    words = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\n",
    "    words = sorted(list(set(words)))\n",
    "\n",
    "    labels = sorted(labels)\n",
    "\n",
    "    training = []\n",
    "    output = []\n",
    "\n",
    "    out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "    for x, doc in enumerate(docs_x):\n",
    "        bag = []\n",
    "\n",
    "        wrds = [stemmer.stem(w.lower()) for w in doc]\n",
    "\n",
    "        for w in words:\n",
    "            if w in wrds:\n",
    "                bag.append(1)\n",
    "            else:\n",
    "                bag.append(0)\n",
    "\n",
    "        output_row = out_empty[:]\n",
    "        output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "        training.append(bag)\n",
    "        output.append(output_row)\n",
    "\n",
    "    training = numpy.array(training)\n",
    "    output = numpy.array(output)\n",
    "\n",
    "    with open(\"data.pickle\", \"wb\") as f:\n",
    "        pickle.dump((words, labels, training, output), f)\n",
    "\n",
    "tensorflow.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model11 = tflearn.DNN(net)\n",
    "\n",
    "try:\n",
    "    model11.load(\"model.tflearn\")\n",
    "except:\n",
    "\n",
    "    model11.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "    model11.save(\"model.tflearn\")\n",
    "\n",
    "\n",
    "#==============end====chatbot=================\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'random string'\n",
    "\n",
    "\n",
    "@app.route('/index')\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "\n",
    "@app.route('/register', methods=[\"GET\",\"POST\"])\n",
    "def register():\n",
    "    if request.method == \"POST\":\n",
    "        name = request.form.get(\"name\")\n",
    "        email = request.form.get(\"email\")\n",
    "        mobile = request.form.get(\"mobile\")\n",
    "        gender = request.form.get(\"gender\")\n",
    "        dob = request.form.get(\"dob\")\n",
    "        username = request.form.get(\"username\")\n",
    "        password = request.form.get(\"password\")\n",
    "        cursor.execute(\"insert into userdetails(fullname,gender,mobile,email,dob,username,password) values('\"+name+\"','\"+gender+\"','\"+mobile+\"','\"+email+\"','\"+dob+\"','\"+username+\"','\"+password+\"')\")\n",
    "        connection.commit()\n",
    "        #return render_template('/index')\n",
    "        return redirect(url_for('/index'))\n",
    "    else:\n",
    "        #return render_template('index.html')\n",
    "        return redirect(url_for('/index'))\n",
    "\n",
    "\n",
    "@app.route('/login', methods=[\"GET\",\"POST\"])\n",
    "def login():\n",
    "    msg = ''\n",
    "    if request.method == \"POST\":\n",
    "        session.pop('user',None)\n",
    "        username = request.form.get(\"username\")\n",
    "        password = request.form.get(\"password\")\n",
    "        cursor.execute('SELECT * FROM userdetails WHERE username = %s AND password = %s', (username, password))\n",
    "        account = cursor.fetchone()\n",
    "        #print(account)\n",
    "        if account:\n",
    "            session['user'] = account[1]\n",
    "            #return render_template('home.html')\n",
    "            return redirect(url_for('duplicatedetection'))\n",
    "        else:\n",
    "            # Account doesnt exist or username/password incorrect\n",
    "            msg = 'Incorrect username/password!'\n",
    "    #return render_template('index.html', msg=msg)\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "#logout code\n",
    "@app.route('/logout')\n",
    "def logout():\n",
    "    session.pop('user')\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "@app.route('/home')\n",
    "def home():\n",
    "    if 'user' in session:\n",
    "        return render_template('home.html', user=session['user'])\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "@app.route('/aboutus')\n",
    "def aboutus():\n",
    "    return render_template('aboutus.html')\n",
    "\n",
    "\n",
    "@app.route('/contactus')\n",
    "def contactus():\n",
    "    return render_template('contactus.html')\n",
    "#bot start======\n",
    "\n",
    "@app.route('/duplicatedetection')\n",
    "def duplicatedetection():\n",
    "    if 'user' in session:\n",
    "        return render_template('duplicatedetection.html', user=session['user'])\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "\n",
    "@app.route(\"/get\")\n",
    "def get_bot_response():\n",
    "    userText = request.args.get('msg')\n",
    "    results = model11.predict([bag_of_words(userText, words)])\n",
    "    print(results)\n",
    "    results_index = numpy.argmax(results)\n",
    "    print(results_index)\n",
    "    print(results[0][results_index])\n",
    "    oppred=results[0][results_index]\n",
    "    outdatagot = \"No duplicate Question found for this query\"\n",
    "    if oppred>0.7:\n",
    "        tag = labels[results_index]\n",
    "        #outdatagot = \"\"\n",
    "        for tg in data[\"intents\"]:\n",
    "            if tg['tag'] == tag:\n",
    "                responses = tg['patterns']\n",
    "                responseop=\"\"\n",
    "                for ik in responses:\n",
    "                    responseop=responseop+ik+\",\"\n",
    "                outdatagot = \"input matches with question \\n \"+responseop+\" with \"+str(oppred)#random.choice(responses)\n",
    "                print(outdatagot)\n",
    "        return str(outdatagot)\n",
    "    else:\n",
    "        outdatagot=outdatagot+\" \"+str(oppred)\n",
    "        return str(outdatagot)\n",
    "\n",
    "\n",
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [stemmer.stem(word.lower()) for word in s_words]\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "    return numpy.array(bag)\n",
    "model11.load(\"model.tflearn\")\n",
    "#bot end======-------------\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #app.run(debug=\"True\")\n",
    "    app.run('0.0.0.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
